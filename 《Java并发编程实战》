※线程安全性
1、并发历史：
   早前的计算机没有操作系统，只有单一的程序从开始至结束得出结果，并直接操作计算机的各种资源
操作系统的出现允许多个任务同时执行，从而提升了同一时段不同资源的利用率，增加了不同用户共同使用的公平性，同时，在实现上编写多个程序同时执行也比单个程序逐一执行所有任务要简单便利

2、并发问题解决：
   当多个线程同时访问一个   状态会发生变化的变量    时，如果没有同步，就可能会有错误，解决的办法包括取消共享、固定这个变量的状态，或者在访问这个变量时使用同步
对于开发并发程序，应当首先考虑代码能够正确的运行，再考虑性能上的优化，因为一旦发生并发异常，要确定具体的错误点比较困难，而且在设计上应该要求封装性要好一些

3、安全性：
   多个线程不管执行的时间次序如何，也不需要在外面采用额外的同步，在调用一个类时，这个类都能够表现出正确的行为，那么这个类就是线程安全的类
无状态的对象一定是线程安全的，其中无状态的对象不包含线程间的共享域，因此在其他外部调用线程来看，这个类的状态是不会变化的

4、竞态条件：
   在并发条件下，由于不同的线程执行顺序，导致不同的结果，就是竞态条件，Race Condition---- 恶性竞争
导致竞态条件的的原因是--先检查当前的状态再执行接下来的操作，譬如在自增操作中，需要先检查当前的值，然后进行加一处理，但是检查完当前值之后，这个值可能立即就被其他线程更改了，所以后续基于这个旧值所做的操作已经无效。(可能不是非常恰当，判断条件状态的属于竞态条件，但是具体到判断数值的属于数据竞争)。

5、原子性操作：
   当前线程以原子（不可被其他线程打断）方式执行完对同一个状态的所有复合操作。

   如果有一个类是由原子变量组成时，这个类也未必就是线程安全的，还需要原子变量彼此之间没有状态的约束。如，Atomic a  与 Atomic b，假设变更b为真时，需要判断a是否为真，那么，在判断当前的a已经为真后，执行b为真的变更前，a可能已经被其他线程改了状态，所以b的执行操作无效。
所以，要保证状态的一致性，就要保证对所有相关的状态变量进行原子操作。

在同步中涉及到多个状态相关的变量，这些变量使用的同步锁应该也是同一个才可以

6、同步锁的重入：
    一个类假定包含了三个同步方法，两个线程去访问这个类的同一个对象实例，当①号线程已经进入了这个对象的其中一个同步方法①时，这个对象其实就已经被加锁一次，这时②号线程想进入这个对象的任意一个同步方法都会被阻塞，但是②号线程可以进入这个对象没有使用同步的方法或者块，如果①号线程在同步方法①中又调用了同步方法②，①号线程是可以直接重入的，此时这个对象被加锁的次数累增1，同时JVM会标明当前对象锁的持有线程是谁，直到这个对象被加锁的次数为0，才说明这个对象被锁释放了，然后再允许其他线程进入持有。
如：父类有一个使用了synchronized修饰的同步方法，子类继承父类，并覆写父类的这个同步方法，如果，子类的同步方法里面存在通过super.method()去调用父类同步方法时，相对于对于外部线程，通过父类创建实例对象( FatherClass father = new SonClass() )去调用子类的同步方法，是允许子类里面再去调用父类同步方法的，因为对象锁都是父类对象，属于同一个。

※对象的共享
1、可见性：
   在没有使用同步的情况下，一个线程对另外一个线程的共享变量操作以及代码的执行顺序都无法准确的获知，因为读取的值，在被其他线程修改后有可能是已经失效并且后续去读取的线程由于缓存等原因也不会再更新读取，而代码的执行顺序是因为编译器、处理器会对代码的执行逻辑进行优化调整，也就是“重排序”
线程一
number=1
ready=true
线程二
while(ready)
  System.out.println(number)
可能输出为0也可能永远不输出

对于未使用同步手段或者volatile的64位double、long变量，由于JVM将读写操作分成两个高低32位操作，如果在多线程环境下，当一个线程正在高32位写，低32位在等待被更新时，另外一个读线程有可能会读取到最新的高32位值与仍未被修改的低32位值，所以64位变量需要使用同步手段或volatile

2、volatile：
   使用了volatile的变量，编译器与处理器不会对执行顺序进行重排序，也不会使用缓存优化导致读取不到最新变更的值
使用synchronized进行同步相当于读写锁，也就是指无论在当前线程进行读或者写时，只要先获取了对象锁，都需要其他线程进行阻塞等待这个线程完成读写。而volatile只是相当于读锁，在有线程进行变量读取时，需要其他写入的线程进行阻塞等待，不能同时进行数据变更，而在有线程在进行变量写入时，则允许其他线程并发执行写入

volatile无法保证原子性操作，如自增型的，因为它允许其他线程并发地修改，当一个线程已经读取到最新值，准备写入时，其他线程抢先写入了，导致数据不一致

JVM启动时，可以指定-client与-server两种参数启动方式，一般开发、测试环境指定-client，生产环境指定-server模式，不过由于-server模式会进行更多的执行策略优化，所以有些bug在生产环境会出现，在开发、测试环境未必会出现，所以，需要在测试环境也指定-server模式，用于重现生产环境

3、发布与逸出
发布Publish是指把对象或者类的内部方法、变量公开给其他类或者线程去调用，而公布了不应该公布的内容就是逸出（Escape），所以，需要注意程序良好的封装性，以避免逸出带来的潜在风险

this引用逸出
   创建一个对象实例时，当对象内的构造函数还没有执行完，如果此时在构造函数中新建一个线程，那么这个新线程是可以访问当前对象this的，但是这个this显然还没有构建完成，如类内部的一些变量还没有被赋值，不能被使用，所以逸出了。
解决方法为：在类内部新建一个静态的初始化方法，把要引用this对象的代码从构造函数中抽离出来，然后先调用类构造函数完成对象状态的初始化，再使用this，最后把创建好的对象进行返回给外部去使用。
public class A{
  private int num;
  private A(){
     new Thread(new Runnable(){
         public void run(){
               System.out.println(this.num);  //把这个移出来
         }
     }).start();
     num=1;
  }
  public static  A  newInstance(){
      A a = new A();
      System.out.println(a.num);  //放到这里
      return a;
  }
}

4、线程封闭
   把原本线程共享的数据，封闭到线程私有内存中，不需要再同步，这个就是线程封闭，也可以理解为资源的本地化管理

Ad-hoc线程封闭
   通过应用程序来承担线程封闭的职责，不开放公共资源出来

栈封闭
   通过申明线程私有的局部变量，来实现对象的封装，如：在方法中申明一个HashMap私有private变量，并且指向一个new出来的内存块，这个内存块对象只有一个引用，那就是通过局部变量来访问的，所以实现了虚拟机栈的局部变量访问封闭。

ThreadLocal
   对于被ThreadLocal修饰的变量，将为所有使用该变量的线程都单独保存一份独立的内存副本，并通过变量的get()方法与set()方法，获取到专属于每个线程的操作值

5、不变性
   当对象在完成创建后，不可再变更，这样的不可变对象一定是线程安全的

Final
   final修饰变量时，只能初始化一次，可以在声明的时候不赋值，但在构造函数需要完成赋值，也就是不可变的对象，是线程安全的；
   final修饰对象时，对象的引用指向不能再变，但是指向的实例值时可以变化的，也就是不可变的对象引用，不是线程安全的；
如 final student = new Student("LiMing");   student.alertName("WangMing");
final修饰类时，这个类不能被继承，final修饰方法时，类哪怕被继承，但是这个方法也不能被覆写。

   单纯的不可变对象，如：final int a，不需要使用额外的同步就可以保证线程的安全，JVM会在对象a构造函数初始化时就保证了线程的安全性，但是如果是final指向了一个内部状态值可变的对象，那么这个对象的状态就需要在修改时使用同步，多线程环境下，有个原则，凡是能够设定为final类型的，尽量使用final保证减少可以变化的状态。

   在不使用同步的情况下，通过final加volatile，能够实现多个状态相关联的变量被线程安全的访问，其中，final起到的作用是保证了final修饰的变量跟对象，在创建后，不会被其他线程修改（如下示例中final修饰的对象之所以安全，是因为那个对象内存被栈封闭了，保证final对象线程安全），volatile保证final修饰的可变对象的值，在构造函数里面被赋值后，内存可见，其他线程可以及时读取到。
class  final Test{
  private final int key;
  private final BigInteger[] values;  //final修饰一个对象，并且对象指向的实例可以变化的，所以不能保证线程安全

  public Test(int k,BigInteger[] v){
      key=k;   //final修饰的变量，在构造函数初始化完以后就不可以再变化了，保证常量
      values = Arrays.copyOf(v,v.length);//由于 values指向了copyOf 新开辟的一块内存区域，并把v的值进行复制赋值，这个内存区域只有一个对象引用，并且被类的私有域封装了，值不能再变，所以最后还是是线程安全的。
  }
  
  public int getValue(int k){
      if(k==key){ //由于是常量，保证接下来执行的动作依赖的前提条件k==key一直是正确的，不怕中途被改
           return Arrays.copyOf(values,values.length);//返回时要注意还是要复制内存空间的方式返回，不要直接返回对象，否则这个对象就被暴露了，有被修改的风险
      }
      return null;
   }
}

public static void main(String args[]){
    private volatile Test   test= new Test(null,null);  //volatile保证final BigInteger[] values 此修饰的可变对象在构造函数赋值时，内存可见，因为后续要不断地反复修改test指向
    new Thread(
      new Runnable(){
          while(1){
                test = new Test(1,数组值); //由于后续不能再修改key value的值了，所以每次只能把test对象指向到新创建的内存中，并重新初始化赋值
                test.getValue(随机传入一个值);
          }
      } 
    ).start();
}

6、安全发布对象
如果没有使用同步，发布对象有可能并不安全
public class ObjectModel{
   private int n;
   public ObjectModel(int n){
        this.n  =  n;
   }
   public void ifNotInitialYet{
       if(n!=n){  //当一个线程在初始化此对象实例时，另外一个线程同时访问这个对象之后，调用此方法，有可能会发现第一次读取的值（超基类Object会给n赋默认的值，如：0）与第二次读取的值（n已经完成构造函数的初始化）不一致
            System.out.println(" not initial yet ! ");
       }
   }
}

不安全发布：
public ObjectModel  objectModel;
public void initialize(){
   objectModel = new ObjectModel(1);
}
当其他线程也同时访问此对象objectModel时，可能会发生下面的情况
①objectModel引用的值时失效的，也就是还没有指向new出来的新域
②objectModel引用的值是最新的，但是内部状态的值却是失效的，也就是n还没有初始化完成赋值1
③调用objectModel的ifNotInitialYet()，会发现，第一次读取的值与第二次读取的值不一致，也就是刚好经历了初始化


※对象的组合
1、Java监视器模式：将类内的所有可变变量、对象都进行私有化private封装，并在访问这些私有变量、对象的时，使用公有public同步方法

2、线程安全的委托实现：将类的线程安全委托给已经是线程安全的类，通过线程安全类的组合，来搭建起一个大的线程安全类

※基础构建模块

1、同步容器类：
   指通过将类里面的状态，也就是变量、对象进行私有private封装，并且在每个对外公有public方法中都使用同步，保证每次只有一个线程能访问与修改容器的状态（Java监视器模式）

传统的同步容器类代表：Vector、HashTable以及由Collections.synchronizedXXXX工厂方法创建的容器

存在的问题：
   如果对同步容器类存在复合操作，如：先获取容器的长度size，再获取容器下标为size-1的值，也就是最后一位的值，那么，如果获取完size之后，另一个线程把最后一个下标对应的值删除了，这个时候当前线程再去获取这个最后一位值就会报错ArrayIndexOutOfBoundsException异常

   针对此同步容器类的问题，java5.0以后给出了for-each去遍历同步容器类（本质都是使用Iterator去遍历容器），不过不能保证在遍历时能够不被其他线程修改同步容器的值，只是能够发现此类的异常，原理是保持对容器长度的计数，发现被变更了则在下标遍历到已删除的值之前，就提前报异常，譬如遍历到下标N的值时，发现同步容器已经被其他线程并发删除了部分的数据，就会报错ConcurrentModificationException，实现所谓的“及时失败”

解决办法：
   凡是对同一个同步容器的对象都要使用对象锁进行同步，保证只要是同一个同步容器对象，所有线程操作时都需要进行同步，不允许出现一个线程在判断完这个同步容器对象的状态后，在接下来的操作之前，又被其他线程修改了这个同步容器的值
示例：
public static Object getLast(Vector list){
   synchronized(list){
       int lastIndex = list.size-1;  //由于获取最后一位值函数与删除最后一位值函数都使用了list锁，当前获取到lastIndex值后，如果是同一个对象list， remove会被阻塞，无法同时删除。
       list.get(lastIndex);
  }
}
public static Object removeLast(Vector list){
   synchronized(list){
      int lastIndex = list.size-1;
      list.remove(lastIndex);
   }
}

注意：同步容器的toString()方法也包含了对容器本身的下标遍历操作，也就是一个个字符转化，所以在toString时，不能被其他线程修改同步容器的值，这种是隐藏的容器下标遍历

2、并发容器类：
   并发容器用于改善同步容器，同步容器只允许线程串行访问来保证线程安全，但是并发容器可以允许线程并发地访问

ConcurrentHashMap
   针对HashMap 这个线程不安全容器的改良版，能够允许多线程并发访问修改，原理为按照key值，将value划分不同的区域段，每个区域存储一定数量的value，当拿到key值，按照特定的哈希的映射规则，就可以知道它的value应该被安置在哪个区域段中，然后，再将这些区域段用 不同的锁 进行同步，当线程1在修改第一段区域时，会锁住第一段区域，但是，可以允许线程2并发地去修改第二段区域的，也就是所谓的“分段锁”

CopyOnWriteArrayList
     当需要修改容器值时，先复制容器的值到另外一个内存空间，在复制好的内存空间中完成容器副本值的修改，然后再以原子方式把副本值覆盖回原来的容器值（容器值每次被更新后版本号就会累增，如果当前线程在复制出来进行副本修改时，现有的容器值又被其他线程更快的完成了修改，那么当前的线程会发现覆盖回去时，容器值的版本号对不上原来获取到的，所以放弃已有的修改，重新复制，再修改，也就是所谓的乐观锁？）

3、阻塞队列BlockingQueue(BlockingQueue是一个接口)
     阻塞队列包含put、take方法，如果队列满了，调用put的线程会被队列阻塞，直到队列有空间给put新值时，如果队列空了，调用take的线程会被队列阻塞，直到队列有新值时，这种队列的设计主要是给生产者消费者使用的。
     其中，有界的队列长度是固定的，无界队列不会被存放满

常见的BlockingQueue实现类包括：
LinkedBlockingQueue（队列形式）
ArrayBlockingQueue（数组形式）
   属于LinkedList与ArrayList的优化版本，都是FIFO（fist in fist out）先入先出队列
PriorityBlockingQueue |praɪˈɒrəti|
   属于自定义优先级的队列
SynchronousQueue |ˈsɪŋkrənəs|
   没有数据存储空间，维护的是生产者线程组队列与消费者线程组队列，当一个新的生产者put任务时，它会被阻塞排队，直到有消费者进来take任务，直接把生产者手中的任务领走时，生产者线程才能继续执行下去，这样有个好处就是生产者能及时知道它的任务已经被消费者领取处理了。

ArrayDeque
LinkedBlockingDeque
    java 6中新增的容器，最大的特点就是不仅可以在队列头插入、删除，也可以在队列尾进行插入和删除，也就是所谓的“双端队列”
实现的场景为在生产者-消费者中，每个消费者都拥有自己的双端队列用于存放任务，这样可以避免所有的消费者去争抢同一个任务队列，并且当一个消费者在完成自己的双端队列的所有任务时，可以去另外一个消费者双端队列的尾部中抽取任务出来完成，之所以强调尾部，是为了避免在头部跟另外一个消费者线程争抢任务，也即是所谓的工作窃取[work stealing]

4、同步工具类
    当线程调用工具类的方法时，这个类有能力去阻塞当前的线程，等到条件成熟时才放行，这样的工具类就是同步工具类，比如阻塞队列，当线程调用take、put方法时，如果队列已空或者已满，就会阻塞线程，所以阻塞队列是同步工具类
同步工具类分以下几种：

4.1闭锁
   特点是无论哪个线程调用此类的方法时，都会被阻塞，直到设定的外部特定条件满足时，统一放行所有线程，并且不再阻塞
CountDownLatch
创建CountDownLatch对象时设定阀值N，线程调用了await()方法会被阻塞，当countDown()被调用了N次，递减为0时，所有线程的await()阻塞处会被唤醒，同时往下执行 
public void unifyBegin(){
final CountDownLatch startGate = new CountDownLatch(1);

for(int i = 0; i < 3; i++ ){ //开启三个线程
   Thread thread  = new Thread() {
         public void run(){
             try{
                startGate.await();  //统一进行阻塞
                System.out.println("yep,I am running now,together");
             }catch(Exception e){}
         }
   } ;
   thread.start();
}

//准备三个线程同时启动
startGate.countDown();
}

4.2 FutureTask
  特点是  在创建FutureTask线程任务，并且启动子线程之后，当前线程调用get方法会被阻塞，直到子线程执行完，返回指定的数据类型，也就是任务的执行结果。其中，FutureTask类是一个实现类，Future只是是一个接口。通过Future可以控制任务的生命周期，包括取消任务，查询任务的执行结果等等。
示例：
private final  FutureTask<String>  future = new FutureTask<String>(//构建一个FutureTask<T>线程任务，在它的构造函数FutureTask<T>(Callable<T>)中传入一个新创建的Callable实例，并且重新实现Callable接口的call方法，用于说明子线程的具体执行任务
   new Callable<String>(){
      public String call(){
         return "OK";  //表示该线程执行完后，返回指定的数据类型String
     }
  }
);

private final Thread thread =  new Thread(future);
thread.start();

future.get();//将会被阻塞，直到future线程任务执行完，返回String数据

4.3 信号量
   对于特定的资源，比如连接池总的可用连接，可以设定为N个，那么信号量也就有N个，每个请求线程过来，都需要申请获得信号量，方式为调用方法acquire()，如果当前有可用连接，那么就获得了许可，线程继续往下执行去获得连接，总数N表示当前的可用连接，需要递减1，如果信号量已经为0，即没有可用连接，那么调用acquire()的请求线程就会被阻塞，直到再有可用连接。当请求线程完成连接，释放此信号量时，调用release()
示例：
Semaphore sem = new Semaphore(num);//设定当前的信号量总数
sem.acquire();//申请获得信号量，没有会被阻塞，有的话信号量总数减一，并允许往下执行
sem.release();//表示当前已经执行完成，释放信号量，信号量总数加一


4.4 栅栏
    栅栏与闭锁相似，不过闭锁是用于等待外部的条件满足了，再一起往下执行，而栅栏是等待所有线程都到齐了，再一起往下执行
4.4.1 CyclicBarrier
    主线程中声明一个CyclicBarrier对象，在构造函数中传入栅栏一次放行的线程数目，并且可以在单次栅栏放行以后，触发一个异步的线程用于执行放行后的逻辑，最后，子线程去调用await函数时，将会被阻塞，等到指定数目的子线程们都到达了await这一步，再一起往下执行
主线程执行：
CyclicBarrier barrier = new CyclicBarrier( 3 ,
     new Runnable(){
            public void run(){
                  System.out.println("在完成了一次栅栏放行线程的操作后，自动触发这个子线程");           
            }  
     }
);
子线程执行：
barrier.await(); //个别的子线程在执行到此处时，会先被暂停执行，等到3个子线程都执行到此处时，再一起唤醒后同时执行下去

4.4.2 Exchanger
    主要是用于两个线程之间的数据交换，当A线程调用exchange()方法后，会被阻塞，等到B线程也执行到exchange()后，两个线程之间进行数据交换，这种交换是指双方的对象映射的内存空间进行调换，也就是A的数据对象指向B的数据内存空间，B的数据对象指向A的数据内存空间，然后再继续一起往下执行
主线程执行：
Exchanger<List<String>>   exchanger  = new Exchanger<>();
需要将这个exchanger对象传入到A、B线程对象的构造函数中
new A( exchanger ).start();
new B( exchanger ).start();

A线程执行：
class A extends Thread{
    Exchanger<List<String>>   exchanger = null;
     public A(  Exchanger<List<String>>  exchanger  ){
           this.exchanger = exchanger;
     }
  
     public void run(){
         List<String> list = new ArrayList<>();
         list.add("A");
         list=exchanger.exchange( list );
     }
}

B线程执行：构造与A相似
list<String>list=new ArrayList<>();
list.add("B");
list.exchanger.exchange(  list ); //先到达的被阻塞，直到A也执行到这里，进行数据交换，再往下执行


4.5 设计一个安全、高效的包含缓存的计算类--这是一个漂亮的程序，值得欣赏
public interface Computable<A,V>{  //A表示运算时传入参数的数据类型，V表示运算后返回结果的数据类型
    V compute( A  arg ) throws InterruptedException;
}

public class Memoizer<A,V> implements Computable<A , V>{ //实现此计算类，加入高效的缓存
    private final ConcurrentMap<A , Future<V>>   cache  = new ConcurrentHashMap<A , Future<V>>();  //用于缓存已经算好的结果，其中这个Map的key为运算时传入的参数变量，value为一个Future<V> 线程任务，这个任务就是去完成运算，并保留运算后的结果V，如果还没有运算完，那么就阻塞线程，等待它运算完返回结果，如果运算中途崩了，那么就需要从Map中移除掉，重新运算
    private final Computable<A,V> c; //指明具体的运算模型，比如是加法，减法或者因式分解之类的

    public Memoizer(Computable<A,V> c){//构造函数传入具体的运算模型
        this.c = c;
    }
  
    public V compute( final A arg ) throws InterruptedException { //重新覆写运算方法，加入缓存
          while(true) {  //为了防止中途发生异常，所以搞个循环，如果发生异常了，保证能再循环重新算，直到得出结果后返回为止
                  Future<V> future = cache.get(arg); //尝试根据运算的参数变量，获取相应的线程任务，看之前是否已经跑过这个运算
                  if(future == null){  //没有从缓存中取出来，说明是还没有跑过这个运算
                           FutureTask< V >   futureTask = new FutureTask<V> ( //新建一个运算的线程任务
                                  new Callable<V>() {
                                        public V call() throws InterruptedException {
                                            return c.compute(arg);
                                        }
                                  }               
                            );
                            future = cache.putIfAbsent(arg,futureTask); //此处会进行并发控制，如果缓存内还没有这个线程运算任务，那么就进行缓存并且返回为空，已经有了这个运算任务就直接返回缓存的运算任务，中间不会允许多个线程都去新建这个运算任务
                            if(future == null){ future = futureTask ; futureTask.run() ;} //如果缓存中没有这个运算任务那么就需要在缓存后，启动这个新建的线程任务去跑运算。
           
                           try{
                                 return future.get(); //开始阻塞，等待运算任务计算出结果
                           }catch(Exception e){
                                cache.remove(arg,future); //发生了异常，有问题的运算任务就需要移除掉，然后重新循环运算
                           }
                  }
           }
     }   
}


运用这个包含缓存的计算类：
Computable<BigInteger,BigInteger[]> detailComputable = new Computable<BigInteger,BigInteger[]>(){
       public BigInteger[] compute(BigInteger arg) { //实例化计算类的接口，实现里面的计算方法，说明具体的计算方式
             return factor( arg ); //计算方式可能是一个因式分解，譬如，arg传入6，返回一个 BigInteger[] 数组：[0]下标存储2 ，[1]下标存储3，也就是6=2*3
       }
}
Computable<BigInteger,BigInteger[]> cache = new Memoizer<BigInteger,BigInteger[]>(detailComputable); //给有缓存的计算类传入具体的计算方式

cache.compute( 6 ); //计算6的因式分解

※任务执行
     使用线程池Executor能够解决单线程串行来排队执行的响应慢问题，又能规避针对一个请求就去新建一个线程的资源无限制消耗，可以把线程池看做是一种消费者，主线程作为生产者提交任务给消费者线程池，线程池负责安排线程把任务消费完成掉，从而，把任务的提交，跟任务的执行分离开来。

1、创建线程池的类型包括下面几种，Executor是一个接口，new的时候返回了它的具体实现类实例：
Executor   exec  =  Executors.newFixedThreadPool()
      创建一个限定最大线程数的线程池，线程数还没有达到限定值时来了新任务就去新建线程，如果达到了限定值，那么新任务就先放着，先等着有线程空闲下来了再去执行，这种线程池不会回收空闲线程，所以到了限定值，就一直维持着这个线程数
Executor   exec  =  Executors.newCachedThreadPool()
     创建一个没有固定线程数的有弹性线程池，如果有空闲的线程，就会去回收，有新任务时就创建新的线程，而且新建的数目没有限定
Executor   exec  =  Executors.newSingleThreadExecutor()
     最多只能创建一个线程的线程池，如果线程被异常结束了，会再去新建一个来替代，但保证只有一个，有两个好处，一个是保证了任务队列能够按先后顺序或者其他优先级顺序来被执行，第二个是这种单线程能够保证共享资源的安全处理，哪怕被其他线程并发介入，也能保证对象被安全地封装到线程中。   
Executor   exec  =  Executors.newScheduledThreadPool()
    创建一个限定最大线程数的线程池，这个线程池在执行任务时能够设置定时的时间去执行或者延长多久去执行

2、线程池的关闭方式包括下面几种：
interface ExecutorService extends Executor  
  Executor是一个接口，ExecutorService本身也是一个接口，并且继承了Executor，ExecutorService添加了一些支持线程池取消任务的方法
shutdown()
  能够平缓的关闭线程池，不再接受新的线程任务，但是会等到已经提交过来的线程任务执行完
shutdownNow()
  不仅不再接受新的任务，并且会尝试去取消所有在运行与已经提交但还未运行的任务，并将已经提交还未运行的任务返回，正在运行的任务将丢失
awaitTermination()
  等待线程池到达终止状态，期间调用这个方法的线程会被阻塞进行等待
isTerminated()
  单次询问这个线程池是不是已经终止了

3、想要获取提交给线程池任务的执行结果，包括发生异常时，希望捕捉异常信息，这时候需要用submit方法，它支持传入承载任务的Callable，并且返回一个Future对象，Future可以用来控制这个任务的生命周期，同时发生异常时，也可以通过get方法来捕捉ExecutionExecption异常，但是如果用了execut方法并且传入Runnable来承载任务，那么就没有相关任务的执行反馈信息
也就是：Future = exec.submit(Callable);     exec.exucute(Runnable);

4、对于一个大任务，如果想切分小的任务并且加入多线程并行来处理，要注意每个子任务的粒度大小，不能相差太远，比如完成任务一需要1000s完成任务二只需要1s，那么这种并行处理就没有什么意义了，实际上只是比串行排队执行减少了1s，但是却增加了程序的复杂性。

5、如果向线程池提交了一批的任务，并且希望都返回执行结果，那么这个时候需要用到新的线程池类型CompletionService来获取返回结果，CompletionService是一个接口，它的作用就是组合了Executor线程池与一个阻塞队列，其中，线程池用于提交并且执行任务，然后再把执行结果放到阻塞队列中供返回，其中CompletionService的take()是阻塞的，直到一个任务执行完成时才把结果返回，poll()是非阻塞的，访问一次，有任务执行完了就返回，没有就返回空。返回的结果按各个任务执行完成的顺序，而不是提交的顺序。
      ExecutorCompletionService是CompletionService的具体实现类。
示例如下：
ExecutorService executor = Executors.newFixedThreadPool(5);
CompletionService<Integer>  completionService = new ExecutorCompletionService<Integer>(executor);//作用就是相当于给线程池executor加上一个阻塞队列BlockingQueue，把任务执行返回的结果都保存在队列中，供后续去查询，其中返回结果为<Integer>
for(int i = 0; i<10 ; i++){
     completionService.submit(  //需要传入一个Callable的对象实例
           new Callable<Integer>(){  
                  public Integer call(){ //声明Callable对象实例后，需要实现这个接口的call方法
                        return i;
                  }
           }
     );
}
for(int i = 0 ; i<10 ; i++){
    completionService.take(); //从CompletionService的内部阻塞队列中获取执行结果
}

6、如果提交任务到线程池后，在等待任务执行完返回结果时，可以在等待时给任务的执行加个限定时间，Future.get(时间间隔，时间单位)  在给定的时间内还没有等到执行结果，就抛出一个TimeoutException，捕捉try-catch到这个异常以后，需要把这个任务再取消掉Future.cancel( true )，不要妨碍接下来的流程。
示例：
Future<Integer> future = exec.submit(new Task());//这里为了简便，省略了线程池创建与任务的定义，加了一部分伪代码
future.get(1000,SECONDS);//在1000秒内没有等待到这个任务的执行结果就抛出TimeoutException，future相当于这个任务线程的句柄，通过这个相当于汤勺的手柄可以去控制线程任务的执行
future.cancel( true );//通过try-catch捕捉到异常后，取消任务

对于批量的任务提交后，希望能加个限定时间，可以用invokeAll()方法，超过时限的任务将会被取消
List<Future<Integer>> futures = exec.invokeAll(List<task>,Long time,TimeUtil unit);


※取消与关闭 
    只要有线程还在运行，那么JVM都不能正常退出，当一个线程A尝试去终止另外一个线程B时，不能简单粗暴的直接停止，譬如已经被废弃的Thread.stop()，这样会造成B线程无法完成必要的清理工作，如果有占用共享变量的话也会立即被释放，造成共享变量的状态混乱。
     Thread.interrupt()作用为A线程通知B线程运行应该停止了，也就是A去修改了B线程的中断状态标志位为true，如果B线程此时正好处在阻塞状态，譬如B调用了sleep()、wait()、join()这些方法，这种类型的阻塞状态会定时去检查B的中断状态标志位，发现为true时，阻塞的方法内就会抛出InterruptedException异常，并结束阻塞状态，这时就应该在try-catch中做好后续的处理措施。并不是所有阻塞都会去检查中断状态标志位，阻塞队列BlockingQueue的take()与put()方法也会去检查，而共享资源的同步阻塞不会去检查。
     如果B线程在正常运行时，被A线程调用了Thread.interrupt()，B可以无视中断状态标志位的更改继续运行，也可以通过Thread.currentThread.isInterrupted()来判断中断状态标志位，为true时给出停止运行的响应。
     interrupted()用来清空中断状态标志位，并返回清空前的状态值boolean，可以用在线程响应中断之后去清除中断状态标志位
    中断设计出来的初衷是为了取消任务，停止线程的运行

1、响应中断的策略
    当A线程去中断B线程时，假如B线程的任务方法中 有调用 支持中断的阻塞方法( 如，wait()、sleep()、join() 会抛出InterruptedException )，B的任务方法在响应A的中断指令时，可以用两种方法来响应A，一是把阻塞方法抛出的InterruptedException再往上抛给A线程去处理，二是B线程按照A的指令，虽然阻塞方法抛出异常后就继续执行了，但B要主动在try-catch-finally中调用interrupt()来修改自己的中断状态标志位，想要响应及时的话就在catch中进行中断自己，但是如果B还有重要任务，就在B线程内部设置个中断变量，并在finally最后根据这个中断变量来决定是否Thread.currentThread().interrupt()。
     去中断一个线程之前，需要知道这个线程响应中断指令的策略是什么。

2、通过Future来中断线程
 Future future = exec.submit(Runnable task);  
 future.cancel( true );
如果已经不再需要线程的执行结果，那么及时的中断线程（目标是取消任务）是个良好的习惯
其中Future.cancel(Boolean mayInterruptIfRunning ) 遇到不能处理中断的任务，就应该在线程还没有启动时，设置false，取消任务，如果线程可以处理中断，那么当线程已经在运行时，设置true，也可以取消任务。

3、关闭不响应中断的阻塞
  对于那些不会响应中断的阻塞类型，比如I/O阻塞，同步锁阻塞（但是Lock除外，它在等待同步锁时会响应中断请求），如果是单线程，可以自定义覆写Thread.interrupt()方法，如果是线程池，可以改写Future.cancel()方法，在里面去停止此类阻塞，从而达到发出中断请求时，哪怕阻塞本身不会响应，借助覆写后的中断取消方法，也能去处理这类阻塞。
示例：
3.1改写Thread.interrupt()
public class CancelThread extends Thread {
      public void interrupt(){
            try{
                   socket.close(); //覆写interrupt方法，添加额外的取消操作，如IO阻塞关闭
             }catch(IOException e){}
             finally{
                   super.interrupt(); //调回原来基类Thread的interrupt方法
             }
        }
        public void run() {  .....任务方法.....}
}    
 
3.2通过Future.canal()覆写来取消特定的阻塞
//继承Callable<T>也就可以作为形参传入线程池中执行，并且新增两个方法，目的是通过newTask方法返回一个RunnableFuture类，包含线程任务call方法与控制线程cancel或者get等等，RunnableFuture构建出来了就可以直接放到线程池执行函数execute()去执行任务
public interface newCancellableTask<V> extends Callable<V>{ 
    public void cancel();
    public RunnableFuture<V> newTask();//生成RunnableFuture，只不过这个RunnableFuture的构建过程会指定用上面自己写的cancel方法来覆盖原来的
}

//实现类，取消阻塞任务的具体实现
public class cancleSocketTask<T> implements newCancellable<T>{
    public void cancel(){
        socket.close()
    }
    public RunnableFuture<T> newTask(){  //FutureTask是RunnableFuture的实现类，RunnableFuture继承了Runnable与Future
           return new FutureTask<T> (this) {//构建FutureTask主动去覆写原来的cacel方法
                public boolean cancel( boolean mayInterruptIfRunning ){
                       try{
                              cancelSocketTask.this.cancel();//构造FutureTask，覆写cancel时，先调用自己的cancel再去调用基类的cancel，实现阻塞的自定义取消
                         }finally{
                               return super.cancel(mayInterruptIfRunning);
                         }
                }
           }
     }
}

//上面两个方法是为了在线程池中去覆写newTaskFor，根据特定的callable来生成指定的
public class CancellingExecutor extends ThreadPoolExecutor{
    protected<T> RunnableFuture<T> newTaskFor(Callable<T> callable){
        if(callable instance of CancellableTask)
              return ((CanncellableTask<T>) callable).newTask(); //是CancellableTask生成的实例对象，就通过它自己的newTask方法来生成RunnableFuture，否则还是用自己的newTaskTask
        else
              return super.newTaskFor(callable);
   }
}

4、关闭生产者消费者模型的思路
    假定的场景是生产者属于外部调用方，有多个，消费者只有一个，需要关闭消费者服务时，要保证，消费者线程在关闭前要消费完队列中的所有任务，并且确认不再有生产者进来存放任务，这样才是安全的关闭
private boolean isShutDown;
private int produceNum=0;

生产者方法：
synchronized (this){//使用同步是为了避免isShutDown与produceNum被同时修改，或者被看到的值不同步
    if( isShutDown ){
        throw new IllegalStateException();//抛出异常后，被方法捕获，直接返回不受理
    }
    produceNum++;  //判断当前还没有关闭，就要对进来的生产者数目进行累增1，说明消费者得处理produceNum次才能把消费队列任务清空
}
queue.put(msg);

消费者方法：
while(true){
    synchronized(this){
          if(isShutDown  && produceNum == 0 )
              break;       //只有确认状态被关闭了，并且当前消费队列已经被清空了，才能关闭消费者线程
    }
    queue.take();
    synchronized(this){ produceNum -- };
}

      如果生产者有N个并且消费者也有多个时，可以采用毒丸对象来关闭生产者消费者，当决定关闭时，每个生产者都往消费队列中放入一个特定的任务（毒丸），消费者在收到第N个毒丸时就表示此时生产者没有再往队列中放任务，而消费者也已经处理完之前的所有任务，可以关闭线程。

5、修补ShutdownNow的任务丢失bug
    当调用ShutdownNow强制关闭线程池时，对于已提交还未执行的任务在被取消后会返回，但是正在执行被强制取消的任务就丢失了，所以，需要搜集这些运行时被强制关闭的任务，以便下次重新跑时能继续执行下去。
重新改写ExecutorService的execute执行方法
public class TrackingExecutor extends AbstractExecutorService{
    private final Set<Runnable>  tasksCancelledAtShutdown  = Collections.synchronizedSet(new HashSet<Runnable> ());//创建同步容器
    public void execute (final Runnable runnable){
          exec.execute(new Runnable(){ //通过重新覆写execute方法，改造一个新的Runnable实例，run调用原来的，不过后面加入中断后的记录
                  public void run() {
                      try{  runnable.run() }finally{
                            if(isShutdown() && Thread.currentThread.isInterrupted() ){
                                    tasksCancelledAtShutdown.add(runnable);
                            }
                      }
                  }
           )
    }
}

6、线程池内的线程异常监控
     ThreadPoolExecutor线程池内会有一个工作者线程，每当有任务提交后，由这个工作者线程创建新线程去执行此任务，并且会加上catch Throwable来捕获RuntimeException异常，用于发现线程池内发生异常的子线程，及时关闭有问题的线程并把错误抛出来---这个是不需要自己动手的

    此外，还可以通过实现一个UncaughtExceptionHandler，当JVM监控到线程由于未捕获异常而退出时，会把异常信息报告给该异常处理器实现类
在母线程去捕捉子线程异常的示例：
 public class ExceptionLogger implements Thread.UncaughtExceptionHandler {
     public void uncaughtException(Thread t,Throwable e) {
          logger.log(   t.getName ,e  );
    }
}
exceptionLogger.uncauthtException(thread,excepiton);


在子线程构造函数内部去捕捉自身异常的示例：
public class MyThread extends Thread{
   public MyThread(Runnable runnable){ //线程类的构造方法中设置setUncaughtExceptionHadler()来捕捉异常
         setUncaughtExceptionHandler(
              new Thread.UncaughtExceptionHandler(){
                    public void  uncaughtException(Thread t,Throwable e){
                         logger.log(  t.getName , e );
                    }
              }
         );
   }
   public void run(){....}
}



7、JVM关闭
   JVM启动的线程包括普通线程与守护线程，区别是，JVM关闭时，会等普通线程全部关闭后再关闭，而守护线程可以不需要管，直接抛弃，其中由普通线程创建的线程默认也是普通线程，由守护线程创建的是守护线程，如果普通线程都结束了，JVM也会自动关闭
   对象的finalize方法是在对象被内存回收时调用的终结方法，C++里面用来内存释放，而java只是归还一些占用的句柄，比如文件句柄，由于是给JVM回收线程调用的，多线程的环境比较难保证线程安全，所以谨慎使用
 “关闭钩子”线程是JVM在执行最后关闭操作时，用来做扫尾工作的执行者，比如清理磁盘，删除临时文件等，除非JVM被强行关闭，否则都会运行用来关闭的钩子线程


※线程池的使用
1、线程饥饿死锁
    线程饥饿死锁是指，假定在有三个线程数的线程池中，三个任务已经占满了线程数，并且还有两个任务在等待执行的队列中排队，如果这三个任务此时又阻塞了，需要等待还在排队中的两个任务的结果，那么就发生了因为线程数目不够而导致的死锁

比如：在newSingleThreadExecutor()的单线程线程池中，如果已经有一号任务在跑，此时一号任务新开了二号任务，把它提交给同一个线程池，并等待二号任务的执行返回结果，就会导致饥饿死锁，因为一号任务已经占用了线程，二号任务只有一号任务执行完了才能占用这个单线程，而一号任务又需要二号任务的结果才能执行下去。

2、设计线程池的线程数大小
如果是计算比较多的任务，线程数大小应该为CPU核数+1个，保证CPU充分利用，并且还有备胎
如果是阻塞比较多的任务，比如等待I/O，那么线程数大小应该更多些，因为阻塞时没有充分利用资源，其他线程可以占用
如果是共享资源数有限制，比如数据库的连接数，那么就应该以数据库连接数为准，防止争抢
或者动态调整，设置不同的线程数，观察系统的CPU利用率，来决定线程数

计算公式：
CPU核数=Runtime.getRuntime().availableProcessors();

最佳线程数 =    CPU核数     *    CPU的目标利用率   *     (1+ 线程等待时间/线程CPU运算时间)
线程等待时间是指每个线程平均的阻塞时间，比如等待I/O ，线程等待阻塞得越久，说明能开的线程数越多，防止CPU空闲浪费资源
线程CPU运算时间是指每个线程平均占用CPU运算的时间

这个公式总体而言是以CPU核数为基准，目标利用率越高，线程数越接近CPU核数，同时，线程等待阻塞得越久，越需要开多些线程


3、线程池参数
public ThreadPoolExecutor(①、基本大小   int corePoolSize ,    
                                                     ②、最大大小   int maximumPoolSize , 
                                                     ③、存活时间   long keepAliveTime 
                                                     ④、任务队列   BlockingQueue<Runnable> workQueue,
                                                     ⑤、线程工厂   ThreadFactory threadFactory,
                                                     ⑥、饱和策略   RejectedExecutionHandler handler )

①、
   corePoolSize是线程池的线程数基本大小，有任务提交才开始创建，直到corePoolSize个后不再增加也不再减少，如果想要一开始就创建线程可以调用prestartAllCoreThreads，如果想要基本大小的线程数也能被回收，可以用allowCoreThreadTimeOut，来允许基本大小的线程空闲超时后被回收。

②、
   maximumPoolSize是线程池的线程数极限最大值，当   工作任务队列满了   时才从corePoolSize个开始，继续创建，直到maximumPoolSize个极限值，超出corePoolSize个的线程数将开始计算空闲下来的时间，如果过了keepAliveTime时间，那么就开始回收，直到回落到corePoolSize个

示例：
    对于newFixedThreadPool，基本大小与极限大小是同一个值，并且不设置keepAliveTime超时时间，这样线程池的线程数就能维持一个恒定的值
    对于newCachedThreadPool，基本大小为0，极限大小为Integer.MAX_VALUE，keepAliveTime超时的时间固定为1分钟，这样的线程池就能保证可以动态扩增跟回收空闲，不过这样的线程池有个bug，那就是一开始，任务队列必须要被塞满后，才开始创建新的线程，队列没被塞满以前，都得不到处理，而newCachedThreadPool因为使用了同步移交的SynchronousQueue，也就是提交任务的线程必须快速等到线程池的消费者线程亲手领取任务，从而规避了这种情况。

④、
     BlockingQueue<Runnable>是线程池的任务队列，用来缓存外部线程提交给线程池的任务，可以包括有界队列、无界队列以及同步移交（SynchronousQueue，提交任务的线程必须等待空闲的消费者线程到来，并亲手移交任务）

     newFixedThreadPool与newSingleThreadPool采用了无界的任务队列，也就是说只要这两种线程池内所有的线程都处于忙碌状态，新提交的任务将在任务队列中无限制的累增堆积。
    如果对线程池的处理效率有足够的信心，也就是线程池是没有线程数限制的，或者当处理不过来时可以快速回绝任务，并且希望提交的任务能够被快速执行完，那么就可以像newCachedThreadPool一样使用SynchronousQueue来实现任务的快速交接，好处是节省了中间的任务被缓存的时间，由提交任务的线程直接交接任务给线程池内的消费者线程。
   如果线程池采用了有界的任务队列，那么就需要考虑，当任务队列已经被塞满时，怎样处理再有新的线程来提交任务？这时需要考虑到饱和策略，具体包括：
AbortPolicy 中止策略 ，当发现任务队列已经满了时，抛出RejectedExecutionException异常给提交任务的线程，供它去处理。
CallRunsPolicy  调用者运行策略，当发现任务队列已经满了时，让提交任务的线程自己执行自己提交的任务。
DiscardPolicy  抛弃策略，当发现任务队列已经满了时，悄悄把这个任务给扔了。
DiscardOldestPolicy  抛弃最老任务策略，当发现任务队列已经满了时，就把队列当中最老的任务给扔了，如果不是FIFO任务队列，而是优先级的任务  队列，就会把当前队列中优先级最高的扔了。
设置的示例：
ThreadPoolExecutor executor = new ThreadPoolExecutor(10 , 10 , 0L , TimeUnit.MILLISECONDS , new LinkedBlockingQueue<Runnable>(CAPACITY));//有界任务队列，类似一个newFixedThreadPool
executor.setRejectedExecutionHandler( new ThreadPoolExecutor.CallerRunsPolicy() );//设置调用者运行策略

⑤、
    线程工厂是线程池拿来生产子线程实例的，改造它以后，可以利用它来定制不同特性的线程，使得线程池新建的线程都具有特别的属性
public interface ThreadFactory{  //线程工厂是一个接口
  Thread newThread(  Runnable r ); //形参传入任务后，生产并返回线程对象的方法，这里应该是public吧
}
    改造线程工厂时需要实现线程工厂接口，并且构造一个线程类，用于线程工厂返回新线程实例
改造的示例：
public class SpecialThreadFactory implements ThreadFactory{
   private String PoolName;
   public  Thread  newThread(Runnable runnable){
       return new SpecialThread(runnable,poolName);//构造并返回特别的新线程，并且还可以传入线程池的名字，加入到新子线程的名称中
   }
}
public class SpecialThread  extends Thread{
    public SpecialThread( Runnable  runnable, String poolName  ){
       super(runnable , poolName); //在此处需要调用基类Thread的构造函数，也就是说，任务的执行还是要交给Thread去跑，但是可以在外面做一层封装，加一些定制的功能
       定制功能***
    }
    public void run(){
       super.run(); //通过基类去跑任务
       定制功能****
    }
}

4、
    线程池ThreadPoolExecutor支持的功能
ThreadPoolExecutor支持在创建完毕后再修改它的相关属性
if (  exec  instanceof   ThreadPoolExecutor ){     //怕线程池exec不是ThreadPoolExecutor生成的对象，所以需要判断下
    ((ThreadPoolExecutor) exec).setCorePoolSize(10);
}
或者通过Executors中的工厂方法unconfigureableExecutorService()来生产   不可以修改线程池属性  的  线程池

ThreadPoolExecutor有三个方法可以在改造覆写后，定制特定的功能，beforeExecute()、afterExecute()是每个新建执行任务的子线程必须调用的方法，子线程开始前调用beforExecute()，子线程结束后调用afterExecute()，线程池结束关闭时会调用terminated()
用法：可以用来记录每个子线程的执行时间
public class TimingThreadPool  extends ThreadPoolExecutor {
    private final ThreadLocal<Long> startTime = new ThreadLocal<Long>();
   
    protected void beforeExecutor(Thread t , Runnable r){
          super.beforeExecutor(t , r); //覆写时也要尊重原有的功能，所以调用基类ThreadPoolExecutor的beforeExecutor()
          startTime.set( Now() );   //每个子线程去调用startTime时，因为它是ThreadLocal的，所以每个线程都有一个专属的值，刚好用来计算不同子线程不同的开始时间
    }

    protected  void afterExecutor( Thread t , Runnable r ){
        super.afterExecutor( t , r );//尊重原创
        long Time = Now() - startTime.get(); //每个子线程获取到的startTime都是专属的
        log.info("execute time"+time); 
    }
}

※GUI的并发研究
涉及到GUI用户图形交互的操作都是单线程运行的


※活跃性问题
    活跃性发生问题是指线程之间不健康的并发状态，不活跃了，如死锁，长时间的阻塞，响应太慢
1、死锁：
    死锁是指  线程彼此之间  都  已经获取了对方想要的资源  并且   希望抢夺对方的资源  而陷入的困境，解决的办法包括：保证线程间获取资源的顺序相同，或者自己在去抢占其他资源时，先释放自己手中的资源。一旦发生死锁只能重启应用程序..

①因为对象加锁顺序导致的死锁：
   当线程A在占有了对象①的锁，去抢占线程B的对象②的锁时，线程B已经占有了对象②的锁，也想去抢占A的对象①的锁。这时，如果设计线程A与线程B抢占对象锁的顺序是一样的，也就是都是先获取对象①的锁，再去获取对象②的锁，那么就可以避免这种互相之间的抢占，而是在抢占资源时一起排队同步。
   解决办法为：通过System.identityHashCode(Object) 来获取对象的唯一哈希数字值，如果要抢占两个对象锁，那就让线程之间都保证对这两个对象的加锁顺序是哈希数值从小到大（或者从大道小）
示例：
public static final Object  bakLock = new Object();  //全局静态备用对象锁
public void transferMoney( final Account source , final Account destination) {  //模拟银行的汇款，从源账户source中扣款，划去目标账户destination

int sourceHash = System.identityHashCode( source );   //计算两个账户对象的唯一哈希数值
int destinationHash = System.identityHashCode( destination );

if( sourceHash <  destinationHash)
     Synchronized ( sourceHash ){  //之所以要对两个对象加锁是为了完成源账户、目标账户的增减款原子操作，不被干扰
          Synchronized( destinationHash ){
                 //源账户扣款 ，目标账户加款
          }
     }
}else if(sourceHash > destinationHash){
     Synchronized( destinationHash ){ //保证每个线程对账号的加锁顺序都是哈希值小的对象开始加锁
         Synchronized ( sourceHash ){ 
                //源账户扣款 ，目标账户加款
         }
    }
}else{
    Synchronized( bakLock ){ //万一哈希值冲突了，也就是值相同了，那就用一个全局的静态对象锁来同步，也就是线程A已经占有了全局锁，就只能它操作这两个特定账户，其他线程只能等待
        Synchronized ( sourceHash ){  
          Synchronized( destinationHash ){
                 //源账户扣款 ，目标账户加款
          }
        }
    }
}

②通过开放调用来防止死锁
    说简单些就是去抢占其他对象锁之前先释放当前占有的对象锁，不要随便使用同步方法，尽量使用同步代码块，因为同步代码块能控制锁住的只是共享变量，其他没必要加锁的就不加，而同步方法加锁覆盖面太广。
class A {
   B b;
   public A(B b){
       this.b = b;
   }
   public void method1(){
         synchronized( this ){//保证外部线程进入method1()后，获取B的对象同步方法锁method2()之前先释放A的对象锁this，如果method1()也用了同步方法，那么就没办法提前释放了，导致占用了A对象锁又去争抢B的对象锁，现在这样做，可以保证method1被开放调用
            //共享变量操作
         }
         b.method2();
   }
}

class B{
   public synchronized void method2(){
       //共享变量操作
   }
}

③限定时间内争抢锁
      通过Lock类的tryLock能够实现限定时间内的争抢锁，如果在规定时间内没有获取到锁那就放弃抢占，并且释放已经占有的资源，稍后再重新尝试抢占。但是如果已经占用的锁比较多，那么要一层一层释放出来比较困难，通常是只有两个锁比较合适，先占用一个锁，再去抢占另外一个锁，如果抢占不了就释放当前已经占用的锁。


④通过线程转储来分析死锁
     当JVM发生死锁时，可以通过给JVM进程发送sigquit信号(  kill  -3  进程号 )来获得线程转储信息，也就是得到各个线程执行的代码堆栈日志，如果发生了死锁，会标识哪个线程在争抢什么资源时发生了死锁，也可以分析哪些锁的竞争比较激烈，如果是IO密集型的，可以通过iostat来分析通信的流量


2、线程得不到执行(饥饿)
     JVM创建的线程默认都具有相同的优先级thread.norm_priority，也可以手动更改个别线程的优先级，JDK中定义的线程优先级一共有10个，JVM将设定好的优先级对应到操作系统层的调度执行先后顺序，但是，不同的操作系统平台解析JDK的线程优先级套路是不一样的，有可能不同的Java优先级被映射到相同的操作系统级优先级，这样就会产生不一致的线程执行调度顺序，有极端情况是，有些被设置了低优先级的线程永远得不到CPU的时钟周期调度，导致被饿死。
    所以，轻易不要修改线程的优先级


3、糟糕的响应
    对于计算量非常大的线程任务，如果本身的重要性又比较低，那么为了不干扰其他重要线程的执行，可以把它的优先级降低，满足其他线程的优先执行。不然，都等着这个大运算量的线程任务计算出结果，会导致应用程序糟糕的响应

4、活锁
   活锁是指线程虽然没有阻滞，但是陷入了无意义的死循环，失去了有效的行动
   比如，线程需要完成一个操作，但是这个操作由于外部原因，一直都会操作失败，线程在失败后进行不断的重试，导致程序陷入死循环。或者，当发生死锁时，两个线程间都是先释放自己的资源，想先满足对方的抢占需求，然后再重试抢占，导致双方都没有执行下去。
  

※性能优化
资源密集型操作：
    表示对某种资源消耗比较多，比如CPU、内存，如果是需要CPU运算比较多，就叫CPU密集型操作。

可伸缩性：
    表示现有的程序架构，在计算所需的资源进行横向扩增时，比如，CPU的处理器核数增加、线程数增加时，程序架构也能相应提高处理效率的伸缩能力。
    伸缩性差的话，增加再多的CPU核数，处理能力也会因为其他短板影响而上不去。
    想要提高可伸缩性，就需要争取把计算并行化，这样就能充分利用计算资源处理更多的任务。

阿姆达尔定律：Amdahl
    加速比 = 1/(  串行占比 + 并行占比/CPU核数  )

   加速比可以理解为随着CPU核数的增长，应用程序处理能力、吞吐能力的飙涨幅度，其中，串行占比表示程序中串行运行的比重，比如使用的同步量占比，串行占比+并行占比等于总体程序量100%，程序的可伸缩性越好，加速比就有被拉升得越高的潜力，加速比取决于串行占比与CPU核数，如果串行占比越低，CPU核数越多，那么加速比就越高，相反，如果串行占比已经占了比较大的比重，再怎么增加CPU核数，加速比的提升也是有限的。
   当然，串行占比只是一个概念性的东西，不能实际的统计出具体值。
   如果使用了10个CPU核数，串行占比10%，总体加速比为5.3，那么，平均下来，每个CPU贡献的加速比为5.3/10  =  0.53，这个也就是CPU的使用率

并行导致的额外开销：
①上下文切换
    当线程数多于CPU核数时，必然会导致CPU的时钟周期轮流使用，所以会涉及到线程间的上下文切换，切换了就会导致性能的损失，可以通过vmstat命令查看   
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache         si   so        bi    bo     in   cs us sy id wa st
 0  0 81394   296   100    1904          0    0        148  24     11    1  9  5 79  7  0

②内存同步
    当使用了同步synchronized与volatile时，会用到内存栅栏来刷新各个线程的缓存，使得数据更改保持一致，因此，会损失一些执行时的缓存优化与重排序优化
③阻塞
    当线程因为等待阻塞太久时，状态会从runnable状态变成waiting或者timed_waiting状态(Thread.getState)，此时，可能会被操作系统挂起，然后进行上下文切换到其他可以执行的线程，这样也会导致性能的损失，但是，如果阻塞刚开始，等待得时间还时间不长，JVM会通过自旋等待阻塞的返回结果（类似于for循环，不断的确认阻塞是否返回了结果）

减少锁的竞争
   如果在一个使用同步的地方，排队获得对象锁的线程数量不多，也就是锁的竞争不激烈，那么JVM会进行优化，比如，实际上只有一个线程会访问的资源，如果使用了同步，那么JVM就会取消同步锁的获取、释放操作，又或者，邻近的同步块，如果用的锁对象都是同一个，那么JVM就会把它们合并到一起来统一获取、释放锁。
   锁竞争激烈的地方，说明排队的线程数多，阻塞的时间被拉长，是程序的性能瓶颈，降低这种竞争的激烈程度就让更多的线程快速执行完，充分利用系统的资源，提升可伸缩性
方法如下：

①缩短锁的持有时间
   缩短锁的持有时间，也就是只对线程间共享的域进行加锁，而不涉及到共享的，就不需要使用同步排队来访问，这样可以保证进入同步锁的时间尽量短，让已经获得锁的线程抓紧执行完后归还锁，从而降低竞争的程度。

②减小锁的粒度
  多个线程争抢同一个关卡锁，如果可以把这个对象锁分成好几个，也就是分解成不同对象的锁，这样多个线程争抢的对象不再统一，不同线程被分流到争抢不同的锁对象，从而降低了同一个锁被竞争的激烈程度，而且线程间的竞争对手也会减少
包含：

锁分解
如：
class Test{
   public synchronized void methodA(){...}
   public synchronized void  methodB(){...}
}
分解成：
class Test{
object a = new Object();
object b = new Object();
public void methodA(){
     synchronized(object a){...}//由原来的统一一个Test对象锁锁住两个同步方法  改成  a对象锁methodA()方法，b对象锁methodB()方法
}
public void methodB(){
     synchronized(object b){...}
}

锁分段
   实现的思想也是减小锁的粒度，只不过是在数据容器中实现的，如：ConcurrentHashMap ，将整个容器内的数据集划分为十六段，每段数据由不同的锁进行同步，当段1被修改时，是可以允许其他段被并发修改的，当获取值value = get(key)时，根据当前的key值，计算映射出应该去哪个段获取它的value值。
  但是它也有个弊端，就是有些操作是针对整个容器的，这个时候需要同时获得16个段的锁对象(嵌套获取)，需要慢慢等了，比如对容器进行clear操作，或者进行容器扩容时，但是像size()，isEmpty()等，就不会加锁访问，允许在读取的过程中被并发地修改，所以返回的不是精确值，这种统计是可以容忍的，因为可以理解为被并发修改了。

③规避高并发修改的热点域
     应当避免使用类似于全局计数器的方式来制造所有线程都需要访问更新的热点，像ConcurrentHashMap的size()统计时，是每个分段分别维护一个统计值，有增删时各自更新各自的统计值，等到需要进行全局size()统计时，汇总各个分段的计数之和，来规避全局的计数统计，并且还加入了缓存，如果各个分段没有更新各自的统计值，就可以继续使用上一次的统计值。

④替代同步锁
     使用其他的方案来替代同步锁的方案，比如ReadWirteLock可以允许并发查询值，同步修改值，原子变量的值更新要比普通的使用同步来更新值，效率要更高一些。

⑤避免使用全局的对象池
   不要为了嫌垃圾回收后又新建对象的麻烦，把所需要的对象建造成一个池循环使用，如果是全局公共的对象池，少不了线程间获取对象时需要使用到同步，这个比自己新建一个对象效率更低

※并发程序的测试
①正确性测试
单元测试
     测试的目标是查看基本的功能点是否满足，提出假设，验证结果，比如，新建立的一个容器，可以验证它是否为空，或者塞入N个值之后，验证容器是否已满。这种基础的功能测试可以通过单线程串行一个个来验证。

阻塞测试
    对预期会发生阻塞的地方，可以采用阻塞测试来验证它是否真的发生过阻塞
如：
final   LinkedBlockingQueue<int>   queue  =  new LinkedBlockingQueue<int>();
Thread thread = new Thread(){
    public void run(){
          try{
                queue.take(); //对于刚创建为空的阻塞队列LinkedBlockingQueue，取值预期会发生阻塞
                 fail();//如果没有阻塞，立马就往下执行了，基本可以判定失败
           }cathch(InterruptedException success){} //当接收到中断指令interrupt()时，会抛出中断异常，被拦截后，说明是成功了，然后退出子线程
    }
}
thread.start(); //启动子线程
Thread.sleep(time); //主线程休眠下，等子线程运行到阻塞的地方，这个time是个经验值
thread.interrupt();//开始发出中断指令
thread.join(time);//主线程在time时间内等待子线程执行完，也就是等着它抛出异常后快速退出，当然，如果是直接跳过阻塞，那么会到fail()
assertFalse(thread.isAlive());//如果子线程还活着，说明还在阻塞状态，没有响应中断，失败了

安全测试
    主要测试的方向是模拟多个线程来并发调用被测试的类，顺序不可预计，看是否会发生数据竞争，产生不一样的结果，争取多处理器环境，并且
线程数多于处理器核数，这样可以频繁上下文切换，或者当调用Thread.yield()时，让出CPU的时钟周期也可以造成更多的上下文切换，以此来制造更恶劣的环境。
    如，测试一个有界缓存队列的线程安全时，思路是创建M个生产者与M个消费者，利用每个生产者线程私有的随机函数（避免若公有时，需要线程阻塞同步）一共产生M个随机数，生产者将这M个随机数插入队列中，并记录插入的随机数总和，消费者并发地从队列中取出这M个随机数，也记录取出的随机数总和，最后总结看插入的校验和是否等于取出的校验和来验证这个队列在并发时是否线程安全。为了避免开出来的子线程按顺序执行了，要保证同时并发跑，就统一设置一个栅栏，等所有线程都到齐，再一起往下执行
如：
class Test{
  CyclicBarrier barrier = new CyclicBarrier( 2 * M +1 );//线程集结后统一放行的栅栏，集结数为生产者数+消费者数+主线程数
  private final AtomicInteger putSum = new AtomicInteger(0); //生产者插入的校验和
  private final AtomicInteger takeSum = new AtomicInteger(0);//消费者取出的校验和
  for(int i = 0 ; i < M ; i++ ){
      pool.execute(new Producer());
      pool.execute(new Consumer());
  }
  barrier.await();//等所有M个生产者线程与M个消费者线程执行执行到预备跑的栅栏1号，再加当前主线程执行到此处，开始放行生产者、消费者
  barrier.await();//等所有M个生产者线程与M个消费者线程执行执行到结束跑的栅栏2号，再加当前主线程执行到此处，第二次放行栅栏
  assertEquals(putSum.get(),takeSum.get());//最后校验插入和与取出和

  class Producer implements Runnable {
      public void run(){
        barrier.await();//预备跑的栅栏1号
          产生一个随机数sum;
        queue.put(sum);//向队列中插入随机数sum
        putSum.getAndAdd(sum);//累计插入的校验和
        barrier.await();//结束跑的栅栏2号
      }
  }

  class Consumer implements Runnable {
      public void run() {
          barrier.await();//预备跑的栅栏1号
          sum=queue.take();//从队列中取出随机数sum
          takeSum.getAndAdd(sum);//累计取出的校验和
          barrier.await();//结束跑的栅栏2号
      }
  }
}

资源管理测试
  主要测试是否合理使用资源，比如申请的内存块在不需要继续使用时取消对象的引用，以便被垃圾回收，如：items[i] = null，通过借助对分析工具，进行操作前的堆内存快照以及操作后的堆内存快照，进行对比，来判断堆内存是否合理使用。

②性能测试
吞吐量测试
   对于生产者消费者的阻塞队列而言，通过测试完成M个任务所需要的时间来计算出平均每秒能完成的任务数，也就是吞吐率（在上面的例子中，只需要在声明栅栏的构造函数中加多一个子线程Runnable，统计第一次放行时刻（起始）、第二次放行时刻（结束），就可以统计完成M个任务总的时间），可以测试的方式包括：增加生产者消费者的线程数，以及增大阻塞队列的容量，达到最佳的吞吐率。如果线程数太少，那么阻塞队列很容易满，生产者线程就很容易被阻塞，导致吞吐率降低。

测试表明：LinkedBlockingQueue比ArrayBlockingQueue在线程数、CPU数增加时具备更加强的可伸缩性，也就是线程数多时，吞吐率更高，这是因为虽然LinkedBlockingQueue虽然在增删时需要进行节点的内存级的分配与回收，但是比ArrayBlockingQueue在内存操作上显得更加的灵活，并且还可以分开头尾的操作，能够更好的降低线程间的竞争，所以可伸缩性更好。

响应性测试
   吞吐量可以测量并发程序单位时间处理的能力，但是也需要知道具体到某个任务，经过并发程序逻辑流程时能够及时返回的时间，也就是响应时间。

性能测试时需要考虑到一些偶发性因素的影响，这种偶发性的因素会导致测试的性能曲线发生测量噪声，也就是突发性变动，比如：
    垃圾回收
    动态编译（程序刚起来时，主要通过解释字节码来执行，但是某个类在频繁被调用后，字节码可能会被改为编译成机器码直接执行）
    执行代码的优化，比如有个方法没有只有一个实现，没有被覆写过，那么虚拟的方法会被转换成直接的调用，但是一旦发现被覆写了，就会放弃已经编译的代码，通常单线程下容易被优化，因此测试代码应当尽量并发执行
    测试环境应当尽量模拟生产的竞争环境，如工作队列外的多线程竞争是否激烈，如果是计算密集型的，那么吞吐量会受限于CPU资源，但是多线程如果没有很多计算任务，整个程序的吞吐量将改为受限于工作队列的同步开销
     对于看似无用的附加测试代码，也就是对程序的结果没有产生影响的，有可能会被编译器删除，因此测试代码应当尽量有输出

找bug的工具：FindBugs

※显示锁
    内置的隐式锁指的是利用synchronized进行加锁的同步块，看不出是进行加锁操作，但是在同步的过程中其实就是实现了互斥的访问。
    显示锁是指用Lock进行很明显的加锁行为，其中Lock是一个接口，ReentrantLock是Lock的实现类
    一般情况下，如果有需要用到显示锁的新特性，才会用显示锁，不然就使用内置锁
Lock的方法包括：
lock()   //普通加锁
lockInterruptibly() //尝试获得锁时可以响应中断
tryLock() //在轮询中每次尝试获取锁，可以防止死锁，获取到锁时返回真，可以响应中断
tryLock(long timeout , TimeUnit unit)//在设定的时间内获取锁，可以防止死锁，获取到锁时返回真，可以响应中断
void unlock() //释放锁
Condition newCondition();   

使用示例：
Lock lock = new ReentrantLock();
lock.lock();
try{ //只要在尝试加锁的操作之后，都说明已经获取到锁了，这个时候需要使用try-finally去释放锁
}finally{
    lock.unlock();  //一定要记住释放锁，不然不会自动清除，后果很严重
}

轮询获取锁：
Class A{
  public Lock lock = new ReetrantLock();  //这是非块结构加锁？
}
Class B{
  public Lock lock = new ReetrantLock();
}
public static void main(String args[]){
    while(true) { //设置一个轮询
         if(a.lock.tryLock()){  //尝试获得A的锁
              try{//进来了，说明就已经获得A的对象锁，需要在最后finally释放A的对象锁
                       if(b.lock.tryLock()){ //尝试获得B的锁
                             try{
                                   .......
                              }finally{b.lock.unlock();}//释放锁
                        }
                 }finally{ b.lock.unlock();)
      }
}


锁中断：
    lock.lockInterruptibly()表示在尝试获得锁时可以响应中断

锁的性能对比：
    内置锁Synchronized与Lock在java5.0时，内置锁Synchronized可伸缩性要比Lock低很多，而在java6.0中，因为有优化内置锁，所以，区别不大

锁的公平性：
public ReentrantLock(boolean fair){
   sync = fair? new FairSync():new NonfairSync();
}
     在声明ReentrantLock时，构造函数可以传入选择是公平锁FairSync还是非公平锁NonfairSync，不传参数默认是非公平锁，synchronized也是非公平锁，区别为，如果是公平锁，无论当前的锁是否被占用，新线程过来想要获取锁都必须进入等待队列中，讲究先后顺序。 如果是非公平锁，因为等待队列中被挂起的线程，在得知锁已经被释放时，唤醒后去获取锁的过程是非常慢的，这个时候如果有新的在运行的线程过来了，可以直接先抢占锁，这对于总体线程的处理效率来说，节省了很多时间。 
      如果是每个线程持有锁的时间比较短，相当于线程队列唤醒的过程中，都能在这间隙期间让在运行的线程快速插队抢占并释放锁，那么非公平的锁比公平锁性能高很多，但是，每个线程持有锁的时间很长时，这种优势就不那么明显了。抢占锁的线程执行慢，唤醒后的线程估计又要被挂起了

读写锁：
  读写锁ReadWriteLock允许多线程并发读，串行写，而不是统一读、写都进行同步，以此来提升效率
使用示例：
private final Map<K,V> map;
private final ReadWriteLock lock = new ReentrantReadWriteLock();//声明读写锁，其中ReentrantReadWriteLock是ReadWriteLock实现类
private final Lock r = lock.readLock(); //获取读锁
private final Lock w = lock.writeLock(); //获取写锁

public V put(K key , V value){
   w.lock();//写锁，当某个线程获取到写锁时，是不允许再被抢占put写锁或者get的读锁
   try{
       return map.put(key , value);
   }finally{
       w.unlock();
   }
}
public V get(K key , V value){
   r.lock();//之所以需要读锁，而不是不加锁，是因为要保证数据的可见性，在并发被修改后，读到的值要是最新的值，当某个线程获取到读锁时，允许其他线程继续获取读锁，但是不允许获取写锁
   try{
       return map.get(key , value);
   }finally{
       r.unlock();
   }
}
公平锁中，读线程必须要同步排队获取读锁，但是如果有写线程进来，优先让它获取写锁。
非公平锁中，写线程与读线程具有同样的等级，在跑的线程比在队列中挂起等待的线程优先获得锁。


※构建自定义对象的线程同步-阻塞工具
①使用synchronized+wait/notifyAll实现同步阻塞
   构建自定义的同步工具时，说白了就是实现阻塞等待的效果，当线程同步排队(synchronized)去获取某个资源时，不满足获取的条件情况下，要怎样安排这个线程？比如想构造一个带有阻塞的队列，当有线程试图排队去给已经满了的队列添加新数据时，要怎样处理这个线程？可以实现的方案包括：
①、返回一个异常给这个线程，说明队列已经满了，让线程自己去容错。
②、让这个线程循环尝试添加数据，发现队列已经满了，就先释放自己已经占用的锁，并且让自己休眠一段时间后，再尝试添加数据。

最理想的办法还是循环尝试下，线程等待休眠后，可以有通知告诉它队列已经不满了，并且唤醒它去添加数据，最为高效。

条件队列：
public class Object{
   public final void wait() throw InterruptException;

   public final native void  notify(); //native method，表示非Java方法实现。

   public final native void notifyAll();

}

    条件队列是指线程在获取到对象的锁前提下，为了等待对象的共享变量到达某个状态时，调用对象的wait方法，使得线程把这个对象的内置synchronized同步锁以及CPU的执行时钟周期让出去，从而陷入休眠状态，因为当前线程已经让出对象锁，其他线程也可以进入这个同步方法中进行wait等待，最终，形成一条为了等待某个对象共享变量到达某个条件而让出同步锁并休眠的线程队列

实现示例：
public synchronized void put(String  value) throws InterruptedException{//需要在获取这个对象同步锁的前提下，没有获取对象锁就去调用wait等这三个方法会报IllegalMonitorStateException异常
    while(isFull()){//判断对象共享变量的状态是否满足特定条件，也就是这个带阻塞功能的数据队列数目是否已满，这个特定条件也被叫做条件谓词

        wait(); //如果还不满足特定条件，这个线程就交还对象锁并进入休眠挂起状态，收到唤醒的通知后，这个线程首先要再排队获得这个对象的put方法同步锁，并且需要再次确认这个状态条件是否满足，所以需要循环判断所谓的条件谓词。

    }
    duPut(value);//如果满足了特定条件，就进行相关操作
    notifyAll();//相当于当子线程自己完成了共享变量的状态改变时(阻塞队列存入了数据)，需要去唤醒因为共享变量状态不满足运行要求而陷入休眠的线程，让它们起来，获得同步锁之后然后重新去判断下条件谓词是否成立
}
public synchronized String take() throws InterruptedException{
    while(isEmpty()){
        wait();
    }
    String value = duGet();
    notrfyAll();
    return value;
}

其中，notify是随机的唤醒一个进入wait休眠的线程，而notifyAll是唤醒所有进入wait休眠的线程，发出唤醒通知后的线程应该尽快释放当前占用的锁，让被唤醒的线程尽快拿到锁，去判断条件谓词。notifyAll是比较低效的，因为唤醒所有等待的线程时，有可能会因为状态条件不满足而让被唤醒的线程重新休眠，但是，又是相对安全的，因为如果让某个线程漏了收到通知，那么这个线程可能会一直休眠下去。


②使用Lock+await/signal实现同步阻塞
   相对于synchronized+wait/notify，Lock+await/signal是显式的同步阻塞
示例：
Lock lock = new ReentrantLock();
private final Condition notFull = lock.newCondition();//申明Condition，一个Condition对象代表一个类型的阻塞队列
private final Condition notEmpty = lock.newCondition();
public void put(String value) throws InterruptedException{
   lock.lock();//在阻塞线程以前，需要这个线程先获得这个对象的锁
   try{
          while(count == queue.length){//进行共享变量状态判定
                 notFull.await(); //阻塞当前的线程
           }
          queue.put(value);
          count++;
          notEmpty.signal();//当前线程知道共享状态已经被自己修改了，就通知其他类型的阻塞队列，signal只通知唤醒一个线程，并且是按照FIFO顺序，signalAll是唤醒所有线程
   }finally{
       lock.unlock();
   }
}
public String take throws InterruptedException{
    lock.lock();
    try{
        while(count == 0){
            notEmpty.await();
         }
        String value = queue.take();
        count--;
        notFull.signal();
        return value;
    }finally{
       lock.unlock();
    }
}

③AbstractQueuedSynchronizer原理
   AQS可以实现同步阻塞的功能，是其他同步类工具的鼻祖，核心包括提供给多线程调用的 获取操作 acquire()与 释放操作 release()
boolean acquire () throws InterruptedException{
    while(当前共享变量状态不允许获取操作){
           if(需要阻塞获取请求){
                  将当前的线程插入到排队队列中
           }else{返回失败}
     }
     更新状态
     返回
}
void release(){
    更新共享变量状态
    if(新的共享变量状态允许已被阻塞的线程获取成功){
        解除一个或多个被阻塞的线程，重新去判断状态
    }
}

其中AQS包含如下方法：
tryAcquire()  tryRelease() 代表在阻塞与释放线程之前，需要线程独占对象的锁，也就是先同步-判断状态-再阻塞
tryAcquireShared()  tryReleaseShared() 代表在阻塞与释放线程时，允许多线程并发进行获取操作
包含共享的状态变量：
getState()  setState()  compareAndSetState() 可以获取共享变量，其中boolean compareAndSetState(0,1)是原子操作，判断状态是否等于 0，等于则赋值 1，更新成功返回true。

   同步工具类在借助AQS实现同步阻塞的功能时，一般的套路都是acquire()、acquireShared()、release()、releaseShared()是同步工具类在封装之后，提供给外部线程去调用的，借此管理阻塞-释放外部线程。
   而try+method开头的（如tryAcquire()）是同步工具类再通过一个内部类去继承AQS来自定义阻塞-释放的规则。例如：规则可以定义为，获取操作tryAcquireShared()返回state值为负数时，表示告诉AQS当前的线程需要阻塞，state值为0时，表示告诉AQS当前的线程是在独占对象锁的前提下放行线程获取的操作，state值为正数时，表示告诉AQS当前的线程是在允许并发的前提下放行线程获取的操作。AQS也会记住每个线程是独占访问还是共享访问。
   tryReleaseShared()释放操作返回true时，表示告诉AQS释放当前被阻塞的线程，返回false则让AQSL继续阻塞线程。

如：构造一个简单的同步阻塞工具类，在未获取释放权限前阻塞线程
public class CloseOpenLatch{
    private final Sync sync = new Sync();
  
    public void await() throws InterruptedException {
         sync.acquireSharedInterruptibly(0);
     }
    public void signal(){  sync.releaseShared(0); }//signal与await是提供给外部线程调用的，形参ignored没有具体作用，调用await的线程将被阻塞，并且是允许并发的阻塞，当调用signal重置了状态变量state为1时，表示允许放行阻塞的线程，从而达到统一开启关闭闸门的作用
  
     private class Sync extends AbstractQueuedSynchronizer {//继承AQS来自定义阻塞-释放的规则
          protected int tryAcquiredShared (int ignored){  //当外部调用acquireSharedInterruptibly与releaseShared会自动转到调用对应内部的tryAcquiredShared与tryReleaseShared，并通过返回state状态值或者ture/false来指挥AQS具体要怎样操作线程，是阻塞还是放行。
                if(getState() == 1){  return 1; } else { return -1;}
           }

           protected boolean tryReleaseShared(int ignored) {
                setState(1);//当状态变量改成1时就放行被阻塞的线程，返回true
                return true;
           }
     }
}

※原子变量与非阻塞同步机制
      使用锁的缺点是当多个线程争抢锁时，对于没有抢占到锁的线程，如果抢占到锁的线程持有锁的时间短，没有抢占到锁的线程会被JVM自旋进行等待，但是，如果抢占到锁的持有时间非常长，那么，没有抢占到锁的线程就会被JVM安排到同步队列中被挂起等待。一旦线程发生了休眠与唤醒，那么造成的上下文切换就会引起很大的系统开销。并且，排队等待的线程在阻塞期间是不能干其他事情的。

     相对于同步容器类去依赖锁与同步，并发容器类之所以能够实现多线程并发的修改，是因为它借助原子变量类来构建非阻塞的算法。原子变量类的原理主要是依赖于处理器硬件层面支持一些原子性操作的特性，也就是读取值-在外部修改值-写入值这种连贯、不可以被中断的操作。
     比如，原子性操作   public  oldValue compareAndSwap( expectedValue , newValue ) ，CAS操作可以判断当前的变量值是否等于一个期望值，如果等于，就赋值新的值，并且返回被更新前的值。之所以这种原子性操作允许并发的执行，是因为，它能够保证多个线程同时执行时，只有一个线程能够执行成功，其他没有执行成功的线程不会陷入等待排队，而是接收到修改失败的返回，这个时候，可以其他线程可以采取的策略包括，重新尝试调用CAS，或者直接绕过。
     同步修改是一种悲观的机制，也就是假定了一个场景，每次线程的修改操作都会有其他线程来干扰，所以必须进行一一同步排队，不能争抢，事实上，当前线程在修改的瞬间，如果没有其他线程来干扰修改，也就是竞争不激烈的话，这种同步就显得比较多余跟低效，而原子操作则是基于乐观的机制，允许线程并发的去修改，如果在修改的瞬间，没有互相干扰，那么就可以共赢，真的发生了干扰，保证只有一个成功，其他的就可以进行事后重试。如果资源竞争不激烈，线程并发度不高，那么原子操作的乐观机制比同步悲观机制效率提升了两倍。
   在本地的计算量少，资源高度竞争的环境，锁的性能要高于原子变量，就好比交通拥塞的交叉口应该使用交通灯，只允许一个方向车次驶入共享区域；本地计算量多，资源竞争不激烈时，锁的性能低于原子变量，就好比交通不拥塞的交叉口应该使用环岛，允许车都驶入共享区域。当然，效率最高的还是ThreadLocal，每部车都有自己的道路，也就取消了资源的共享。

 基于原子变量来构建不阻塞的并发容器：
原子引用类：AtomicReference<T>  a  能够保证涉及到 对象a 对  T的各个实体 的引用 变更 操作 是原子性的操作，并且还能保证获取到的值都是最新的，也就是内存可见性。比如a引用T1修改为引用T2，借助CAS，能够保证是原子性操作。

非阻塞的并发容器-队列算法：ConcurrentLinkedQueue
尾插入示例：
public class LinkedQueue <E> {
   private static class Node<E>{//内部的节点类
       final E value ;//当前节点的泛型值
       final AtomicReference<Node<E>> nextNode;//当前节点的下一个节点指向
       public Node(E value , Node<E> nextNode) {//构造函数初始化节点值与下一个节点的指向
            this.value = value;
            this.nextNode = new AtomicReference<Node<E>> (nextNode);//新建一个原子引用类实例，保存下一个节点的对象
       }
   }
   private final Node<E> zoro = new Node<E>(null , null);//初始化节点
   private final AtomicReference<Node<E>> tail = new AtomicReference<Node<E>>(zoro);//创建一个相对于在队列外部的原子引用类实例，用于保存当前队列的尾部节点对象，初始化时，指向第0号初始节点。

   public boolean put( E value ){  //给队列添加新节点
        Node<E> newNode = new Node<E>( value , null );//新建一个节点，赋值，下一节点定义为空
        while(true){//开始进入循环，表示无论如何要把新节点添加到队列尾部，如果CAS竞争失败了，那就重新来过
               Node<E> curTailNode = tail.get();//从原子引用类实例中获取当前的尾部节点对象
               Node<E> curTailNodeNext = curTailNode.nextNode.get();//获取当前的尾部节点的下一节点
               if(curTailNode == tail.get()) {//判断上次获取的尾部节点是否还等于现在原子引用类实例中保存的尾部节点，不等的话就重新再循环来过
                     if(curTailNodeNext != null) { //说明此刻有其他线程并发给队列添加了新的节点，只是原子引用类实例的指向还没更新到最新的尾部节点，所以，可以帮它更新下，再重新循环来过
                           tail.compareAndSet(curTailNode , curTailNodeNext);//进行CAS更新
                     }else { //说明当前获取的尾部节点对象保存在原子引用类中，期间没有被修改过
                           if(curTailNode.next.compareAndSet(null , newNode)) {//把新节点加入到尾部队列中
                                  tail.compareAndSet(curTailNode , newNode);//更新下原子引用类最新的尾部节点对象
                                  return true;
                            }
                    }
             }
        }
   }
}
实际的currentLinkedQueue是基于AtomicReferenceFieldUpdater反射来实现volatile变量的CAS
class Dog{
   volatile String name = "dog1";
}
Dog dog1 = new Dog();
AtomicReferenceFieldUpdater updater = AtomicReferenceFieldUpdater.newUpdater(dog1 , dog1.name , "test");//类对象，对象的字段，字段值
System.out.println(dog1.name);

避免CAS的ABA问题：
   也就是在进行CAS交换前，线程程T1判断是否为A，为A则赋值C，但是期间判断完是A以后准备进行CAS，线程T2并发介入，将A修改为B，然后又修改回A，为了识别这种情况，加入：AtomicStampedReference或者AtomicMarkableReference来进行区分不同的版本号，也就是第一次读取到A时，加入版本号，进行CAS交换前读取到仍然是A，但是版本号不一致，则说明期间有被修改过。


※Java内存模型
    JVM给程序的一些操作定义了执行上先后顺序的偏序关系，所谓偏序，就是说程序的有些操作两两之间可以拿来做对比，得出谁必须先执行，谁必须后执行，而全序，就是指所有的操作，两两之间拿出来之后都可以做对比，得到必然的先后顺序。偏序关系叫做所谓的Happens-Before，它是JVM天然、固定的程序一些操作排序顺序，不会被优化重排序而扰乱。比如对一个volatile变量同时读跟写时，写必然是排在读前面的。

   有些场景可以借助这种偏序关系来实现隐性的同步线程安全
